# Server Configuration
PORT=3000

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini

# Norce MCP Configuration
NORCE_MCP_BASE_URL=https://customer-slug.api-se.norce.tech/mcp/commerce

# Comma-separated availability statuses passed to product.search
# When empty/whitespace, statusSeed is omitted from MCP calls (no filtering)
# Example: NORCE_STATUS_SEED=1,3
NORCE_STATUS_SEED=

# Replace with your actual application IDs
ALLOWED_APPLICATION_IDS=comma-separate-list-of-allowed-application-ids

# Norce OAuth Configuration
NORCE_OAUTH_TOKEN_URL=https://customer-slug.api-se.stage.norce.tech/identity/1.0/connect/token
NORCE_OAUTH_CLIENT_ID=your-oauth-client-id-here
NORCE_OAUTH_CLIENT_SECRET=your-oauth-client-secret-here
NORCE_OAUTH_SCOPE=stage

# Session Storage Configuration
# SESSION_STORE: 'memory' (default) or 'redis'
# Use 'memory' for local development, 'redis' for multi-instance deployments behind a load balancer
SESSION_STORE=memory
SESSION_TTL_SECONDS=3600

# Redis Configuration (required when SESSION_STORE=redis)
# REDIS_URL=redis://localhost:6379
# REDIS_PREFIX=agent:sess:

# Agent Configuration
AGENT_MAX_ROUNDS=6
AGENT_MAX_TOOL_CALLS_PER_ROUND=3
DEBUG=0

# OpenAI Timeout Configuration (in milliseconds)
# Non-streaming calls: 2 minute timeout (default)
OPENAI_TIMEOUT_MS=120000
# Streaming calls: 5 minute timeout (streams can be longer)
OPENAI_STREAM_TIMEOUT_MS=300000

# OpenAI Retry Configuration
# Non-streaming calls: 2 retries (default)
OPENAI_MAX_RETRIES=2
# Streaming calls: 0 retries (retries on streams are bad UX)
OPENAI_STREAM_MAX_RETRIES=0

# OpenAI SDK Debug Logging (dev-only, may log request/response bodies - use with caution)
# WARNING: Do not enable with real customer data as it may log sensitive information
OPENAI_SDK_DEBUG=0

# Debug Runs Configuration (dev-only, disabled by default)
DEBUG_RUNS_ENABLED=0
DEBUG_RUNS_MAX=200
DEBUG_RUNS_TTL_SECONDS=86400

# Simple Auth Configuration (partner demos only, disabled by default)
# When enabled, POST /v1/auth/simple/token issues short-lived JWTs for widget authentication
SIMPLE_AUTH_ENABLED=0
SIMPLE_AUTH_JWT_SECRET=your-secret-at-least-32-characters-long
SIMPLE_AUTH_JWT_TTL_SECONDS=600

# CORS Configuration
# Comma-separated list of allowed origins for cross-origin requests
# Default: http://localhost:5173,http://127.0.0.1:5173
CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# Request/Body Limits (abuse prevention)
# These limits prevent token abuse by rejecting oversized inputs before any OpenAI call
# BODY_LIMIT_BYTES: Maximum request body size in bytes (default: 131072 = 128 KB)
BODY_LIMIT_BYTES=131072
# MAX_MESSAGE_CHARS: Maximum message character length (default: 4000)
MAX_MESSAGE_CHARS=4000
# MAX_MESSAGE_TOKENS_EST: Maximum estimated tokens (tokens ~ chars/4) (default: 1200)
MAX_MESSAGE_TOKENS_EST=1200
